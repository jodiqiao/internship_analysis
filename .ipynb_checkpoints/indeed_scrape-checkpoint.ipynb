{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indeed.ca scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://medium.com/@msalmon00/web-scraping-job-postings-from-indeed-96bd588dcb4b\n",
    "# referenced code in Mark Salmon's Medium article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://www.indeed.ca/jobs?q=data+intern&l=Toronto%2C+ON\" # test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = soup(page.text, \"html.parser\")\n",
    "#print(bs.prettify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_job_title_from_result(soup):\n",
    "    '''Takes json result and find the job titles in each posting, return a list containing all queried job titles.\n",
    "    '''\n",
    "    job_post = []\n",
    "    for div in bs.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            job_post.append(a[\"title\"])\n",
    "    return(job_post)\n",
    "a = len(extract_job_title_from_result(bs))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_company_from_result(soup):\n",
    "    '''Takes json result and find the company titles in each posting, return a list containing all queried \\n\n",
    "    company titles.\n",
    "    '''\n",
    "    job_post = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        company = soup.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "    if len(company) > 0:\n",
    "        for b in company:\n",
    "            job_post.append(b.text.strip())\n",
    "    else:\n",
    "        sec_try = div.find_all(name=\"span\", attrs={\"class\":\"turnstileLink\"})\n",
    "        for span in sec_try:\n",
    "            job_post.append(span.text.strip())\n",
    "    return(job_post)\n",
    "    \n",
    "a = len(extract_company_from_result(bs))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_location_from_result(soup):\n",
    "    '''Takes json result and find the location in each posting, return a list containing all queried locations.\n",
    "    '''\n",
    "    job_post = []\n",
    "    # getting string in attribute\n",
    "    spans = [item[\"data-rc-loc\"] for item in soup.find_all() if \"data-rc-loc\" in item.attrs]\n",
    "    for span in spans:\n",
    "        job_post.append(span.strip())\n",
    "    return(job_post)\n",
    "a = len(extract_location_from_result(bs))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_salary_from_result(soup):\n",
    "    '''Takes json result and find the salaries in each posting, using string 'Nothing Found' when no salary \\n\n",
    "    infomration is present. Return a list containing all salaries.\n",
    "    '''\n",
    "    job_post = []\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "        try:\n",
    "            s = div.find(name=\"span\", attrs={\"class\":\"salaryText\"}).text\n",
    "            job_post.append(s.strip())\n",
    "        except:\n",
    "                job_post.append(\"Nothing_found\")\n",
    "    return(job_post)\n",
    "a = len(extract_salary_from_result(bs))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract_summary_from_result(soup):\n",
    "    '''Takes json result and find the job summary in each posting. Return a list containing all s.\n",
    "    '''\n",
    "    job_post = []\n",
    "    spans = soup.find_all(name=\"div\", attrs={\"class\":\"summary\"})\n",
    "    for span in spans:\n",
    "        job_post.append(span.text.strip())\n",
    "    return(job_post)\n",
    "a = len(extract_summary_from_result(bs))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ratings_from_result(soup):\n",
    "    '''Takes json result and find the rating in each posting. Return a list containing all ratings.\n",
    "    '''\n",
    "    job_post = []\n",
    "    spans = soup.find_all(name=\"span\", attrs={\"class\":\"ratings\"})\n",
    "    #for span in spans:\n",
    "        #job_post.append(span.text.strip())\n",
    "    \n",
    "    #? only 24/26 \n",
    "    for span in spans:\n",
    "        if \"aria-label\" in span.attrs:\n",
    "                job_post.append(span['aria-label'])\n",
    "        else:\n",
    "            job_post.append(\"No_company_rating\")\n",
    "            \n",
    "    print(spans)       \n",
    "    return job_post\n",
    "\n",
    "# close but no dice; element wrapping rating missing from campanies without rating\n",
    "# no element to identify companies without rating, missed in find_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Linkedin:python+intern\n"
     ]
    }
   ],
   "source": [
    "# per csv\n",
    "max_results = 5000\n",
    "\n",
    "# originally wanted to query by city; have decided to gather location data as it comes ups\n",
    "city_set = [\"\"]\n",
    "\n",
    "# initiate dataframe\n",
    "columns = [\"job_title\", \"company_name\", \"location\", \"summary\", \"salary\"]\n",
    "df = pd.DataFrame(columns = columns)\n",
    "\n",
    "# take user input of keyword in job search ex. data intern\n",
    "query = input(\"Search Linkedin:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city in city_set:\n",
    "    for start in range(0, max_results, 15):\n",
    "        page = requests.get('http://www.indeed.ca/jobs?q=' + str(query) +'&l=' + str(city) + '&start=' + str(start))\n",
    "        bs = soup(page.text, \"html.parser\")\n",
    "        time.sleep(1)  #ensuring at least 1 second between page grabs\n",
    "        for div in bs.find_all(name=\"div\", attrs={\"class\":\"row\"}):\n",
    "            job_post = []\n",
    "            num = (len(df) + 1)\n",
    "            #job_post.append(city)\n",
    "            for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "                job_post.append(a[\"title\"])\n",
    "            company = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "            if len(company) > 0:\n",
    "                for b in company:\n",
    "                    job_post.append(b.text.strip())\n",
    "            else:\n",
    "                sec_try = div.find_all(name=\"span\", attrs={\"class\":\"turnstileLink\"})\n",
    "                for span in sec_try:\n",
    "                    job_post.append(span.text.strip())\n",
    "            spans = [item[\"data-rc-loc\"] for item in div.find_all() if \"data-rc-loc\" in item.attrs]\n",
    "            for span in spans:\n",
    "                job_post.append(span.strip())\n",
    "            spans = div.find_all(name=\"div\", attrs={\"class\":\"summary\"})\n",
    "            for span in spans:\n",
    "                job_post.append(span.text.strip())\n",
    "            try:\n",
    "                s = div.find(name=\"span\", attrs={\"class\":\"salaryText\"}).text\n",
    "                job_post.append(s.strip())\n",
    "            except:\n",
    "                job_post.append(\"Nothing_found\")\n",
    "            \n",
    "            df.loc[num] = job_post\n",
    "\n",
    "df.to_csv(\"python+intern.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
